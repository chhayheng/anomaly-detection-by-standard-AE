# -*- coding: utf-8 -*-
"""client_app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LvgKy8g7nRR0RSssFKkUlquMem_IohIF
"""

from flask import Flask, request, jsonify
import numpy as np
import requests
import os
import google.auth.transport.requests as tr_requests #care! it could cause dependency conflict in requirment.txt during deployment on Cloud Run
import google.auth

app = Flask(__name__)

# --- Configuration for your Vertex AI Endpoint ---
# Replace with the actual URL of your deployed Vertex AI Endpoint
# You can find this in the Vertex AI console under "Endpoints" -> "Endpoint details"
# It will look something like: https://your-gcp-region-aiplatform.googleapis.com/v1/projects/YOUR_PROJECT_ID/locations/YOUR_GCP_REGION/endpoints/YOUR_ENDPOINT_ID:predict
VERTEX_AI_ENDPOINT_URL = ""

# IMPORTANT: Your Anomaly Threshold
# This is the same threshold you determined during your AE model development.
# Example: the 99th percentile of reconstruction errors for normal data.
ANOMALY_THRESHOLD = 1.1360680938823428e-06 # <--- YOU MUST SET YOUR ACTUAL THRESHOLD HERE!

# Obtain credentials automatically using google.auth (works in Cloud Run with default service account)
try:
    # In Cloud Run, google.auth.default() should automatically pick up
    # the service account credentials assigned to the service.
    credentials, project = google.auth.default()
    print("Successfully obtained credentials using google.auth.default().")
except Exception as e:
    print(f"Error obtaining credentials: {e}")
    credentials = None


# --- Helper Function to Call Vertex AI ---
def get_reconstruction_from_vertex_ai(input_data_list):
    """
    Sends preprocessed input data to the Vertex AI endpoint and
    returns the model's raw reconstruction predictions.
    Includes authentication for Vertex AI using the default credentials.
    """
    if not credentials:
         raise ConnectionError("Authentication credentials not available. Ensure default credentials are set up for the Cloud Run service account.")

    # Refresh credentials if necessary (though in Cloud Run, this might be handled differently
    # depending on the credential type obtained)
    # Using google.auth.transport.requests to prepare the authenticated request
    auth_req = tr_requests.Request()
    credentials.refresh(auth_req) # Ensure credentials are up-to-date

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {credentials.token}" # Use the token from the credentials
    }

    # Vertex AI pre-built containers expect "instances" key
    payload = {"instances": input_data_list}

    try:
        response = requests.post(VERTEX_AI_ENDPOINT_URL, json=payload, headers=headers)
        response.raise_for_status() # Raise an exception for HTTP errors (4xx or 5xx)
        predictions = response.json().get("predictions")

        if predictions is None:
            # Check for error details in the response if no predictions are found
            error_detail = response.json().get("error", "No specific error detail provided.")
            raise ValueError(f"Vertex AI response did not contain 'predictions' key. Response: {response.text}. Error detail: {error_detail}")


        return predictions

    except requests.exceptions.RequestException as e:
        print(f"Error communicating with Vertex AI endpoint: {e}")
        # Include response text in the error for debugging
        error_message = f"Failed to get prediction from Vertex AI: {e}"
        if hasattr(e, 'response') and e.response is not None:
             error_message += f". Response text: {e.response.text}"
        raise ConnectionError(error_message)
    except ValueError as e:
        print(f"Error processing Vertex AI response: {e}")
        raise ValueError(f"Vertex AI response parsing error: {e}")
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
        raise Exception(f"Unexpected error: {e}")


# --- Client-Side REST API Endpoint ---
@app.route('/detect_anomaly', methods=['POST'])
def detect_anomaly():
    try:
        # Get the JSON data from the request body
        # We expect a JSON object like: {"data": [[f1, f2, f3, ...], [f1, f2, f3, ...]]}
        # where each inner list is a single, preprocessed data point.
        request_data = request.get_json(force=True)

        if "data" not in request_data or not isinstance(request_data["data"], list):
            return jsonify({"error": "Invalid input format. Expected {'data': [[...], ...]}"}), 400

        input_data_list = request_data["data"]

        # Ensure all input data points have the same expected number of features
        if not input_data_list:
            return jsonify({"is_anomaly": []}), 200 # No data, no anomalies

        # Convert to numpy array for easier manipulation later
        input_data_np = np.array(input_data_list)

        # 1. Call the Vertex AI endpoint
        reconstructions_list = get_reconstruction_from_vertex_ai(input_data_list)
        reconstructions_np = np.array(reconstructions_list)

        # 2. Calculate the reconstruction error
        # Ensure the shapes match for element-wise operation
        if input_data_np.shape != reconstructions_np.shape:
            return jsonify({
                "error": "Shape mismatch between input data and reconstruction. "
                         f"Input shape: {input_data_np.shape}, Reconstruction shape: {reconstructions_np.shape}. "
                         "This often indicates a model or preprocessing issue."
            }), 500

        # Mean Squared Error (MSE) is common for AE reconstruction error
        reconstruction_errors = np.mean(np.square(input_data_np - reconstructions_np), axis=1)

        # 3. Apply anomaly threshold
        is_anomaly = (reconstruction_errors > ANOMALY_THRESHOLD).tolist()

        response = {
            "is_anomaly": is_anomaly,
            "reconstruction_errors": reconstruction_errors.tolist() # Optionally return errors for debugging/analysis
        }
        return jsonify(response), 200

    except ConnectionError as e:
        return jsonify({"error": str(e)}), 503 # Service Unavailable
    except ValueError as e:
        return jsonify({"error": str(e)}), 400 # Bad Request
    except Exception as e:
        # Catch any other unexpected errors
        return jsonify({"error": str(e), "message": "An unexpected server error occurred."}), 500

@app.route('/')
def home():
    return "Anomaly Detection Client API is running. Send POST requests to /detect_anomaly."

if __name__ == '__main__':
    # For local testing, ensure you have your Vertex AI Endpoint URL correctly set
    # You might also need to set GOOGLE_APPLICATION_CREDENTIALS environment variable
    # to a service account key file if running locally and not using gcloud auth.
    # When deployed to Cloud Run, the default service account will be used automatically
    # if it has the necessary permissions.
    port = int(os.environ.get('PORT', 8080))
    # In Colab, the port 8080 might be in use.
    # If running locally for testing, you might need to change the port or stop
    # the process using it.
    # In Cloud Run, the 'PORT' environment variable is typically set to 8080.
    try:
        app.run(host='0.0.0.0', port=port, debug=True)
    except OSError as e:
        if "Address already in use" in str(e):
            print(f"Error: Port {port} is already in use. Please stop the process using port {port} or choose a different port.")
        else:
            raise # Re-raise other OS errors