# -*- coding: utf-8 -*-
"""AE traning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cDpF7hwIW2GJ7K6O4jlddKQUIup0vyZu
"""

import json
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import ipaddress
import numpy as np

from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import roc_curve, auc
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.callbacks import EarlyStopping

EVE_FILE = "" #location log file

try:
    with open(EVE_FILE, 'r') as f:
        log_data = json.load(f)

    df = pd.DataFrame(log_data)
    print("DataFrame created successfully.")
    print(df.head())

except FileNotFoundError:
    print("Error: log_data.json not found. Please upload the file.")
except json.JSONDecodeError:
    print("Error: Could not decode JSON from the file.")
except Exception as e:
    print(f"An error occurred: {e}")

print(df.head())

selected_columns = ['src_ip', 'dest_ip', 'src_port', 'dest_port', 'proto', 'event_type']
df = df[selected_columns]

selected_event_types = ['http', 'tls', 'rdp', 'ssh', 'snmp', 'alert']
selected_event_types_normal = ['http', 'tls', 'rdp', 'ssh', 'snmp']

df_selected = df[df['event_type'].isin(selected_event_types)]
df_normal = df[df['event_type'].isin(selected_event_types_normal)]

# Preprocess both df normal and all

# Encode IPs and protocol for modeling
def preprocess_encode(dfnormal, dfall):
    df_encoded_normal = dfnormal.copy()
    df_encoded_all = dfall.copy()

    df_encoded_normal.drop('event_type', axis=1, inplace=True)
    df_encoded_all.drop('event_type', axis=1, inplace=True)

    # IP as int
    for ip_col in ["src_ip", "dest_ip"]:
        df_encoded_normal[ip_col] = df_encoded_normal[ip_col].apply(
            lambda x: int(ipaddress.IPv4Address(x)) if x else 0
        )
    for ip_col in ["src_ip", "dest_ip"]:
        df_encoded_all[ip_col] = df_encoded_all[ip_col].apply(
            lambda x: int(ipaddress.IPv4Address(x)) if x else 0
        )

    #protocol label encoder
    le = LabelEncoder()
    le.fit(df_encoded_all['proto'].unique()) #make sure LabelEncoder has seen all potential protocol

    df_encoded_normal['proto_encode'] = le.transform(df_encoded_normal['proto'])
    df_encoded_normal.drop('proto', axis=1, inplace=True)
    df_encoded_all['proto_encode'] = le.transform(df_encoded_all['proto'])
    df_encoded_all.drop('proto', axis=1, inplace=True)
    print("=========", df_encoded_normal['proto_encode'].unique(),)
    print("=========", df_encoded_all['proto_encode'].unique(), '\n')

    # Normalize
    scaler = MinMaxScaler()
    scaler.fit(df_encoded_normal) #fit scale only from normal data
    scaled_encoded_normal = scaler.transform(df_encoded_normal)
    scaled_encoded_all = scaler.transform(df_encoded_all)

    return scaled_encoded_normal, scaled_encoded_all

scaled_preprocessed_encode_normal, scaled_preprocessed_encode_test = preprocess_encode(dfnormal=df_normal, dfall=df_selected)

print(scaled_preprocessed_encode_normal, "\n")
print(df_normal, "\n")
print(scaled_preprocessed_encode_test)

# Split normal data
X_train, X_test = train_test_split(scaled_preprocessed_encode_normal, test_size=0.2, random_state=42)

def build_autoencoder(input_dim):
    input_layer = Input(shape=(input_dim,))
    encoded = Dense(64, activation="relu")(input_layer)
    encoded = Dense(32, activation="relu")(encoded)
    bottleneck = Dense(16, activation="relu", name="bottleneck")(encoded)
    decoded = Dense(32, activation="relu")(bottleneck)
    decoded = Dense(64, activation="relu")(decoded)
    output_layer = Dense(input_dim, activation="sigmoid")(decoded)

    autoencoder = Model(inputs=input_layer, outputs=output_layer)
    autoencoder.compile(optimizer="adam", loss="mse")
    return autoencoder

early_stopping = EarlyStopping(monitor='val_loss', patience=5)

# Build and train autoencoder
input_dim = X_train.shape[1]
autoencoder = build_autoencoder(input_dim)
autoencoder.fit(X_train, X_train, epochs=100, batch_size=32, shuffle=True, validation_data=(X_test, X_test), callbacks=[early_stopping])

# Evaluate the model on normal data (already done during training with validation_data)

# Evaluate on anomalous data
reconstructions = autoencoder.predict(scaled_preprocessed_encode_test)

mse = np.mean(np.power(scaled_preprocessed_encode_test - reconstructions, 2), axis=1)

# Might need to define a threshold based on the MSE distribution of normal data
# For example, using the 95th percentile of mse from training data
# threshold = np.percentile(mse_train, 95)  # If mse_train is available from the training data

# Or if no have mse_train, calculate the threshold on the normal test data
mse_X_test = np.mean(np.power(X_test - autoencoder.predict(X_test), 2), axis=1)
threshold = np.percentile(mse_X_test, 10)

# Anomalies are those with mse values above the threshold
anomalies = mse > threshold

print("Reconstruction MSE:", mse)
print("Threshold:", threshold)
print("Anomalies:", anomalies)
print("Number of anomalies detected:", np.sum(anomalies))

# Calculate metrics (accuracy, precision, recall, F1-score)

# Get the predicted labels (anomalies)
predicted_labels = anomalies

# Get the true labels (1 for 'alert', 0 otherwise)
true_labels = (df_selected['event_type'] == 'alert').astype(int)

accuracy = accuracy_score(true_labels, predicted_labels)
precision = precision_score(true_labels, predicted_labels)
recall = recall_score(true_labels, predicted_labels)
f1 = f1_score(true_labels, predicted_labels)

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")
print(f"F1-score: {f1}")

# Calculate the confusion matrix
cm = confusion_matrix(true_labels, predicted_labels)

# Plot the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Predicted Normal', 'Predicted Anomaly'],
            yticklabels=['True Normal', 'True Anomaly'])
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

# Calculate ROC curve and AUC
fpr, tpr, thresholds = roc_curve(true_labels, mse) # Using mse as the anomaly score
auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='AUC Score: %0.2f' % auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC)')
plt.legend(loc="lower right")
plt.show()

"""# FINDING OPTIMAL THRESHOLD

"""

# Calculate reconstruction errors for normal test data
mse_X_test

# Calculate reconstruction errors for the data containing potential anomalies
mse_all_data = mse

# Get the true labels (1 for 'alert', 0 otherwise)
true_labels = (df_selected['event_type'] == 'alert').astype(int)

# Define a range of percentiles to test as thresholds
percentiles = range(10, 100, 5)  # Test percentiles from 80 to 99

results = []
for p in percentiles:
    # Calculate the threshold based on the current percentile of normal test data MSE
    threshold = np.percentile(mse_X_test, p)

    # Predict anomalies using this threshold
    predicted_anomalies = mse_all_data > threshold

    # Calculate evaluation metrics
    accuracy = accuracy_score(true_labels, predicted_anomalies)
    precision = precision_score(true_labels, predicted_anomalies)
    recall = recall_score(true_labels, predicted_anomalies)
    f1 = f1_score(true_labels, predicted_anomalies)

    results.append({'percentile': p,
                    'threshold': threshold,
                    'accuracy': accuracy,
                    'precision': precision,
                    'recall': recall,
                    'f1_score': f1})

# Convert results to a pandas DataFrame for easy viewing
results_df = pd.DataFrame(results)

# Print or visualize the results to compare performance at different thresholds
print(results_df)

plt.figure(figsize=(10, 6))
plt.plot(results_df['threshold'], results_df['precision'], label='Precision')
plt.plot(results_df['threshold'], results_df['recall'], label='Recall')
plt.plot(results_df['threshold'], results_df['f1_score'], label='F1-score')
plt.xlabel('Threshold (Reconstruction Error)')
plt.ylabel('Score')
plt.title('Performance Metrics vs. Threshold')
plt.legend()
plt.grid(True)
plt.show()

# Save the model
# autoencoder.save("autoencoder_model.keras")
autoencoder.export("autoencoder_model_tf")

# You can then load the model later using:
autoencoder = load_model("autoencoder_model.keras")

# prompt: zip /content/autoencoder_model_tf

!zip -r /content/autoencoder_model_tf.zip /content/autoencoder_model_tf
